_target_: project.tasks.unlearning_enpo.UnlearningENPO
_recursive_: false

name: unlearning-enpo

defaults:
  - /text_encoder@text_encoder: qwen3-embedding-4b
  - /embedding_prediction_model@embedding_prediction_model: transformer
  - /data@unlearning_data: rwku-positive-sm

training_module:
  training_warmup_steps: 2000
  training_lr: 0.0001
  training_weight_decay: 0.0
  unlearning_lr: 0.0003
  unlearning_weight_decay: 0.0
  pretrained_model_hook_layer: 29
  clip_grad_norm: 1.0
  beta: 1.0  # eNPO loss parameter
  l1_weight: 1.0  # Weight for L1 (eNPO loss)
  l2_weight: 0.06  # Weight for L2 (KL divergence loss for non-forgetting)
  
  # LoRA configuration for unlearning stage (optional)
  # Set use_lora: true to enable LoRA training instead of full fine-tuning
  # This can significantly reduce memory usage (saves ~35-40GB GPU memory)
  use_lora: true  # Set to true to enable LoRA
  lora_config:  # LoRA parameters (optional, uses defaults if not specified)
    r: 16  # LoRA rank
    lora_alpha: 32  # LoRA scaling parameter
    lora_dropout: 0.05  # LoRA dropout
    target_modules: ["q_proj", "k_proj", "v_proj", "o_proj"]  # Modules to apply LoRA to
    bias: "none"  # Whether to train bias ("none", "all", or "lora_only")

num_other_targets: 3

first_stage_steps: 15000

# Optional checkpoint paths (set to null if not needed)
model_checkpoint_path: null
embedding_model_checkpoint_path: null
reference_model_path: null
reference_embedding_model_path: null

# Model saving configuration
save_embedding_model: false  # Whether to save embedding_prediction_model after last training stage
save_unlearned_model: true  # Whether to save unlearned_model (pre_trained_llm) after last unlearning stage

stages:
  - type: "training"
    steps: ${task.first_stage_steps}
  - type: "unlearning"
    threshold: 0.9  # Optional, kept for backward compatibility
    steps: 1000
  - type: "training"
    steps: 1000
  - type: "unlearning"
    threshold: 0.8
    steps: 1000
  - type: "training"
    steps: 1000
  - type: "unlearning"
    threshold: 0.75
    steps: 1000
  - type: "training"
    steps: 1000
  - type: "unlearning"
    threshold: 0.7
    steps: 1000
  - type: "training"
    steps: 1000
  - type: "unlearning"
    threshold: 0.65
    steps: 1000
  - type: "training"
    steps: 1000
  - type: "unlearning"
    threshold: 0.6
    steps: 1000
  - type: "training"
    steps: 1000
  - type: "unlearning"
    threshold: 0.5
    steps: 1000
  - type: "training"
    steps: 1000
  - type: "unlearning"
    threshold: 0.4
    steps: 1000
  - type: "training"
    steps: 1000
  - type: "unlearning"
    threshold: 0.3
    steps: 1000
  - type: "training"
    steps: 1000
  - type: "unlearning"
    threshold: 0.2
    steps: 1000
